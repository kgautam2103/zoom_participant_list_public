{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zoom_participant_list_utility_functions_public.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8/8pWqw227SsBq8Ae+AUY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgautam2103/zoom_participant_list_public/blob/main/zoom_participant_list_utility_functions_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBLAldvi6w29"
      },
      "source": [
        "def read_worksheet(work_sheet, columns_list):\n",
        "  work_sheet_data = work_sheet.get_all_values()\n",
        "  work_sheet_data_df = pd.DataFrame(work_sheet_data, columns=columns_list)\n",
        "  if work_sheet_data_df.shape[0] > 0:\n",
        "    work_sheet_data_df = work_sheet_data_df.drop(work_sheet_data_df.index[0])\n",
        "  \n",
        "  return work_sheet_data_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzgWrjFsWRmm"
      },
      "source": [
        "def double_encode_uuid(meeting_uuid):\n",
        "  encoded_uuid = urlencode({'id':meeting_uuid})\n",
        "  double_encoded_uuid = urlencode({'id':encoded_uuid[3:]})\n",
        "  return double_encoded_uuid[3:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psg2623cgJqh"
      },
      "source": [
        "def get_participants_list(meeting_uid):\n",
        "  get_participants_url = report_meetings+meeting_uid+'/participants?page_size='+page_size\n",
        "  participants_response = requests.get(get_participants_url,headers=auth_headers)\n",
        "  #print(apac_participants_response.json())\n",
        "  participants_list = participants_response.json()['participants']\n",
        "  next_page_token = participants_response.json()['next_page_token']\n",
        "  while next_page_token != \"\":\n",
        "    new_get_participants_url = get_participants_url+'&next_page_token='+next_page_token\n",
        "    new_participants_response = requests.get(new_get_participants_url,headers=auth_headers)\n",
        "    next_page_token =  new_participants_response.json()['next_page_token']\n",
        "    participants_list.extend(new_participants_response.json()['participants'])\n",
        "  return participants_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcyC0BJ_t47q"
      },
      "source": [
        "def get_poll_answer_df(meeting_uid):\n",
        "  poll_response_url = base_url+'report/meetings/'+meeting_uid+'/polls'\n",
        "  poll_response = requests.get(poll_response_url,headers = auth_headers)\n",
        "  response_list = poll_response.json()['questions']\n",
        "  poll_answer_df = json_normalize(response_list,\n",
        "                                record_path=['question_details'],\n",
        "                                meta=['name', 'email',],\n",
        "                                errors='ignore')\n",
        "  return poll_answer_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISaRBYVyvLeN"
      },
      "source": [
        "def get_poll1_df(poll_answer_df, poll_id):\n",
        "  poll1_df=pd.DataFrame()\n",
        "  poll1_df = poll_answer_df[poll_answer_df.polling_id==poll_id]\n",
        "  if poll1_df.shape[0] > 0:\n",
        "    poll1_df  = poll1_df.fillna(\"\")\n",
        "    poll1_df = poll1_df.reset_index()\n",
        "    poll1_df = poll1_df.drop(columns=['question','polling_id','date_time','email','index'])\n",
        "    poll1_df = poll1_df[['name','answer']]\n",
        "  return poll1_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOcyrEBrvqs0"
      },
      "source": [
        "def get_poll2_df(poll_answer_df, poll_id):\n",
        "  poll2_df = pd.DataFrame()\n",
        "  poll2_df = poll_answer_df[poll_answer_df.polling_id==poll_id]\n",
        "  if poll2_df.shape[0] > 0:\n",
        "    poll2_df  = poll2_df.fillna(\"\")\n",
        "    poll2_df['question'] = poll2_df['question'].apply(lambda x: re.sub('^[\\.\\d\\s]*','',x,flags=re.IGNORECASE))\n",
        "    poll2_df.drop_duplicates(subset=['name','question'],inplace=True)\n",
        "    poll2_df = poll2_df.pivot(index=\"name\", columns=\"question\", values=\"answer\")\n",
        "    poll2_df.reset_index(inplace=True)\n",
        "    poll2_df[['answer1','answer2','answer3']] = poll2_df[['Will you be joining us next weekend?',\n",
        "                                          'Which of the following mid-week followup sessions are convenenient for you? We look forward to see you',\n",
        "                                          'How was your thoughtless state during meditation?']]\n",
        "    poll2_df=poll2_df.drop(columns=['How was your thoughtless state during meditation?',\n",
        "                                'Will you be joining us next weekend?',\n",
        "                                      'Which of the following mid-week followup sessions are convenenient for you? We look forward to see you'])\n",
        "  return poll2_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drq1jU5a5CQz"
      },
      "source": [
        "def get_participants_df(participants_list,event,ref_id_list,ref_name_list,ref_email_list):\n",
        "  participants_df=pd.DataFrame()\n",
        "  participants_df = pd.DataFrame(participants_list)\n",
        "  participants_df = participants_df.drop(columns=['attentiveness_score','failover','customer_key'])\n",
        "  participants_df = participants_df[participants_df.duration>600]\n",
        "  participants_df['id'] = participants_df['id'].apply(lambda x: str(random.randint(1,99999999999)) if x==\"\" else x)\n",
        "  participants_df = participants_df.drop_duplicates(subset=['id'])\n",
        "  participants_df['name'] = participants_df['name'].apply(lambda x: re.sub('^sy[\\.\\s_-]*','',x,flags=re.IGNORECASE))\\\n",
        "  .apply(lambda x: re.sub('[\\.\\s_-]*sy$','',x,flags=re.IGNORECASE))\n",
        "  participants_df = participants_df.drop_duplicates(subset=['name'])\n",
        "  participants_df = participants_df[~participants_df.id.isin(ref_id_list)]\n",
        "  participants_df = participants_df[~(participants_df.name).str.lower().isin(ref_name_list)]\n",
        "  participants_df = participants_df[~(participants_df.user_email).str.lower().isin(ref_email_list)]\n",
        "  participants_df['event'] = event\n",
        "  participants_df['event_date'] = report_datetime\n",
        "  participants_df = participants_df[['event','event_date','id','name','user_email', 'join_time', 'leave_time', 'duration']]\n",
        "  return participants_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaAKpYfj_yNF"
      },
      "source": [
        "def get_rolling_3week_df(rolling_3week_df,final_combined_df):\n",
        "  rolling_3week_df_combined = rolling_3week_df.append(final_combined_df)\n",
        "  rolling_3week_df_combined['event_date'] = pd.to_datetime(rolling_3week_df_combined['event_date'])\n",
        "  rolling_3week_df_final = rolling_3week_df_combined[rolling_3week_df_combined.event_date > report_datetime_3week_before]\n",
        "  rolling_3week_df_final['name']=rolling_3week_df_final['name'].str.lower()\n",
        "  rolling_3week_df_final.drop_duplicates(subset=['event','event_date','name'],inplace=True)\n",
        "  return rolling_3week_df_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4qkB_DbAwU6"
      },
      "source": [
        "def get_weekend_archive_df(weekend_archive_df,final_combined_df):\n",
        "  weekend_archive_df_final = weekend_archive_df.append(final_combined_df)\n",
        "  weekend_archive_df_final['event_date'] = pd.to_datetime(weekend_archive_df_final['event_date'])\n",
        "  weekend_archive_df_final['name']=weekend_archive_df_final['name'].str.lower()\n",
        "  return weekend_archive_df_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq94L-leFgsh"
      },
      "source": [
        "def get_weekend_archive_df_final_filtered_3m(weekend_archive_df_final):\n",
        "  weekend_archive_df_final_filtered_3m = weekend_archive_df_final[weekend_archive_df_final.event_date > report_datetime_3month_before]\n",
        "  weekend_archive_df_final_filtered_3m_frequency = weekend_archive_df_final_filtered_3m.groupby(['name']).agg(count=('name',np.count_nonzero))\n",
        "  weekend_archive_df_final_filtered_3m_frequency.reset_index(inplace=True)\n",
        "  weekend_archive_df_final_filtered_3m_frequency.sort_values(by = ['count'],ascending=False,inplace=True)\n",
        "  return weekend_archive_df_final_filtered_3m_frequency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQzL7GvzG-iq"
      },
      "source": [
        "def get_archive_group_df_max_date_details(weekend_archive_df_final):\n",
        "  weekend_archive_group_df = weekend_archive_df_final.groupby('name')\n",
        "  archive_max_date = weekend_archive_group_df.agg(event_date=('event_date',np.max))\n",
        "  archive_max_date.reset_index(inplace=True)\n",
        "  archive_max_date_final = archive_max_date[archive_max_date.event_date > report_datetime_3month_before]\n",
        "\n",
        "  archive_group_df_max_date_details = pd.merge(weekend_archive_df_final,archive_max_date_final,how='inner',on=['name','event_date'])\n",
        "  archive_group_df_max_date_details.drop_duplicates(subset=['name','event_date'],inplace=True)\n",
        "  archive_group_df_max_date_details.drop(columns=['join_time','leave_time','duration'],inplace=True)\n",
        "  return archive_group_df_max_date_details"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfHfD6zDIp5T"
      },
      "source": [
        "def get_updated_sideroom_details(matched_name_list,archive_group_df_max_date_details):\n",
        "  matched_name_df = pd.DataFrame(matched_name_list,columns=['name','matched_names','score'])\n",
        "  matched_name_df = matched_name_df[matched_name_df.score>90]\n",
        "  matched_name_df_final = pd.DataFrame(matched_name_df['matched_names'])\n",
        "  matched_name_df_final.rename(columns={'matched_names':'name'},inplace=True)\n",
        "  matched_name_df_final_details = pd.merge(archive_group_df_max_date_details,matched_name_df_final,how='inner',on='name')\n",
        "\n",
        "  matched_name_df_final_details['event_date'] = matched_name_df_final_details['event_date'].dt.strftime('%Y-%m-%d')\n",
        "  matched_name_df_final_details['last_event']=matched_name_df_final_details['event_date'].str.slice(0,10)+\" \"+matched_name_df_final_details['event']\n",
        "  matched_name_df_final_details.drop(columns=['event','event_date','id'],inplace=True)\n",
        "  matched_name_df_final_details.sort_values(by = ['name'],inplace=True)\n",
        "  return matched_name_df_final_details"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwGOJnFJYc6"
      },
      "source": [
        "def pivot_rolling_3week_df(rolling_3week_df_final):\n",
        "  group_name_df = rolling_3week_df_final.groupby(['name'])\n",
        "  count_name = group_name_df.agg(count=('name',np.count_nonzero))\n",
        "  max_date = group_name_df.agg(latest_date=('event_date',np.max) )\n",
        "  max_date.reset_index(inplace=True)\n",
        "  count_name.reset_index(inplace=True)\n",
        "  final_max_count = pd.merge(count_name,max_date,on='name')\n",
        "  final_max_count_filtered = final_max_count[final_max_count['count']>1]\n",
        "  return final_max_count_filtered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDd8_QfkKUhC"
      },
      "source": [
        "def get_email_name_ref_df(weekend_archive_df_final):\n",
        "  email_name_ref_df = weekend_archive_df_final[['name','user_email']]\n",
        "  email_name_ref_df.drop_duplicates()\n",
        "  nan_value = float(\"NaN\")\n",
        "  email_name_ref_df.replace(\"\", nan_value, inplace=True)\n",
        "  email_name_ref_df.dropna(inplace=True)\n",
        "  return email_name_ref_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M4PJZGHKv_X"
      },
      "source": [
        "def get_move2side_final(move2side_name_list,final_max_count_filtered):\n",
        "  move2side_name_df = pd.DataFrame(move2side_name_list,columns=['name','matched_names','score'])\n",
        "  move2side_name_df = move2side_name_df[move2side_name_df.score>90]\n",
        "  move2side_name_df_final = pd.DataFrame(move2side_name_df['matched_names'])\n",
        "  move2side_name_df_final_list = move2side_name_df_final['matched_names'].tolist()\n",
        "  final_max_count_filtered = final_max_count_filtered[~final_max_count_filtered.name.isin(move2side_name_df_final_list)]\n",
        "  final_max_count_filtered.drop(columns=['count'],inplace=True)\n",
        "  return final_max_count_filtered"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}